{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "gradual_warmup_scaled_lr_large_minibatch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0305e71d156046be8e6a0d463d7285fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_59e8a587bc994513b51dfe69084a77e3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1e0a45d089344d13a81d94d3840db5b2",
              "IPY_MODEL_11a7a735a642438481b719391fd018cc"
            ]
          }
        },
        "59e8a587bc994513b51dfe69084a77e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e0a45d089344d13a81d94d3840db5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b1157208032b4d9f810208fb41e1cf2e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_508edf9c178c4e96ace562c88a1b218b"
          }
        },
        "11a7a735a642438481b719391fd018cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c0c44431afc54b9495bd80bb56350bee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [10:37&lt;00:00, 267396.72it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29ebe2b89d534b999b5259c19024ed80"
          }
        },
        "b1157208032b4d9f810208fb41e1cf2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "508edf9c178c4e96ace562c88a1b218b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0c44431afc54b9495bd80bb56350bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29ebe2b89d534b999b5259c19024ed80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JjN-50gGJFh"
      },
      "source": [
        "\n",
        "Optimization for machine learning - Mini Project: Large mini-batch scaled learning rate and gradual warm-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSLg8hdbGRvY"
      },
      "source": [
        "## 1. Loading libraries, modules and setting directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zutTbJCSGQzc"
      },
      "source": [
        "## Run this cell if PyTorch is not installed on Colab\n",
        "#!pip3 install torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcZo9dv01Rip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2be5c23-72cd-4654-a64a-f52eeb16c6d9"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount= True)\n",
        "\n",
        "import sys\n",
        "sys.path.append('gdrive/My Drive/Colab Notebooks/OptML/')\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from models import CNN as CNN\n",
        "\n",
        "\n",
        "import time\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc7TzKIqGhr0"
      },
      "source": [
        "### Creating device and checking GPU availability "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2LMdii1k-2X",
        "outputId": "171956d5-6654-4614-e5fb-0253d2c8cd47"
      },
      "source": [
        "### Checking if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNyqYzFc1Rir"
      },
      "source": [
        "# 2. Downloading and normalizing CIFAR 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NmaInPEl7a6"
      },
      "source": [
        "# Normalize dataset and transform into tensor\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "0305e71d156046be8e6a0d463d7285fd",
            "59e8a587bc994513b51dfe69084a77e3",
            "1e0a45d089344d13a81d94d3840db5b2",
            "11a7a735a642438481b719391fd018cc",
            "b1157208032b4d9f810208fb41e1cf2e",
            "508edf9c178c4e96ace562c88a1b218b",
            "c0c44431afc54b9495bd80bb56350bee",
            "29ebe2b89d534b999b5259c19024ed80"
          ]
        },
        "id": "xaFzwFTyl-XH",
        "outputId": "f0e44eac-5e8b-4f05-9a9f-f9b2cf513b06"
      },
      "source": [
        "# Load dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "used_categories = range(len(classes))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0305e71d156046be8e6a0d463d7285fd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT_H1wu01Riv"
      },
      "source": [
        "## 3. Training the network - scaled learning rate and gradual warm-up "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOp_P935G78I"
      },
      "source": [
        "#### Training and testing is set up with a simple validation loop (no CV), looping over for the trainset for a specified number of epochs. At every epoch, the loss, accuracy and time is captured as raw data for later plotting. If GPU was available the model is transferred to the device along with a transformation of the tensor into cuda. To load the data for every batchsize, the torch Dataloader has been utilized. The Cross Entropy loss is used as the loss function and the optimizer used througout the training is the SGD (no momentum or weight-decay). Learning rate equal to 0.001 for all of the small minibatches.\n",
        "\n",
        "### Scaled learning rate\n",
        "#### In this training setup the learning rate is scaled according to the batch size (differing from baseline notebooks) - for the largest batchsizes training becomes meaningless, which is commented and described more thoroughly in the report. This can be contributed to the very large learning rate that arises with the multiplication of the large batch sizes, along with a less sophisticated netork compared the the studies of Goyal et al (2017) and  Masters D., Luschi C. (2018).\n",
        "\n",
        "### Gradual warm-up\n",
        "#### Furthermore a gradual warm-up of the learning rate was implemented to see if this would improve predictions even further. Again training became meaningless at some epoch for the largest batchsizes. Four settings for the warm-up rate has been implemented - exponential, linear, discontinuous (step function) and no warm-up. Used setting is specified in the variable \"gradual_warmup_scheme\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQxeNqqx1Riv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "b0ce9fdf-2c45-4c5e-e733-fa6b7403da57"
      },
      "source": [
        "#from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "# Settings for training\n",
        "power = list(range(5,0,-1))\n",
        "p = 0 \n",
        "batches = [128, 256, 512, 1048, 2048]\n",
        "num_epoch = 70\n",
        "learning_rate_global = 0.001\n",
        "\n",
        "accuracies = []\n",
        "epochs = []\n",
        "time_pr_epoch = []\n",
        "batch_sizes = []\n",
        "loss_pr_epoch = []\n",
        "\n",
        "\n",
        "\n",
        "# Scheme can be either exponential/linear/discontinuous/nowarmup\n",
        "gradual_warmup_scheme= \"exponential\"\n",
        "\n",
        "\n",
        "for BATCH_SIZE in batches:\n",
        "  model = CNN()\n",
        "  model.to(device)\n",
        "  print(\"######### BATCH SIZE = \",BATCH_SIZE,\" ######### \" )\n",
        "\n",
        "  # Learning rate divide\n",
        "  learning_rate = learning_rate_global * BATCH_SIZE\n",
        "  # Initialize trainloader and test loader   \n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                            shuffle=True, num_workers=2)\n",
        "  testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "  criterion =  torch.nn.CrossEntropyLoss()\n",
        "  warmup= (num_epoch*5)/100\n",
        "\n",
        "  print(\"Warmup for \",warmup,\" epochs.\")\n",
        "  for epoch in range(num_epoch):  # Loop over the dataset multiple times\n",
        "\n",
        "\n",
        "      # Setup gradual warmup schemes\n",
        "      if(gradual_warmup_scheme == \"exponential\"):\n",
        "        \n",
        "        # Continue with our initial learning rate after reaching 5% of the epochs\n",
        "        if(warmup==1):\n",
        "          optimizer = optim.SGD(model.parameters(),lr=learning_rate)\n",
        "          print(\"normal LR: \", learning_rate)      \n",
        "        if(warmup>1):\n",
        "          lr_warmup = (learning_rate/(2**warmup))\n",
        "          optimizer = optim.SGD(model.parameters(),lr=lr_warmup )\n",
        "          print(\"warmup LR: \", lr_warmup)\n",
        "          warmup=warmup-1\n",
        "\n",
        "      # Setup gradual warmup schemes\n",
        "      if(gradual_warmup_scheme == \"linear\"):\n",
        "        \n",
        "        # Continue with our initial learning rate after reaching 5% of the epochs\n",
        "        if(warmup==1):\n",
        "          optimizer = optim.SGD(model.parameters(),lr=learning_rate)\n",
        "          print(\"normal LR: \", learning_rate)      \n",
        "        if(warmup>1):\n",
        "          slope = learning_rate/warmup\n",
        "          lr_warmup = epoch*slope\n",
        "          optimizer = optim.SGD(model.parameters(),lr=lr_warmup )\n",
        "          print(\"warmup LR: \", lr_warmup)\n",
        "          warmup=warmup-1\n",
        "\n",
        "      # Setup gradual warmup schemes\n",
        "      if(gradual_warmup_scheme == \"discontinuous\"):\n",
        "        \n",
        "        # Continue with our initial learning rate after reaching 5% of the epochs\n",
        "        if(warmup==1):\n",
        "          optimizer = optim.SGD(model.parameters(),lr=learning_rate)\n",
        "          print(\"normal LR: \", learning_rate)      \n",
        "        if(warmup>1):\n",
        "          lr_warmup = (learning_rate/warmup)\n",
        "          optimizer = optim.SGD(model.parameters(),lr=0.0005 )\n",
        "          print(\"warmup LR: \", lr_warmup)\n",
        "          warmup=warmup-1\n",
        "      \n",
        "      # Setup gradual warmup schemes\n",
        "      if(gradual_warmup_scheme == \"nowarmup\"):\n",
        "        optimizer = optim.SGD(model.parameters(),lr=learning_rate)\n",
        "      \n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      start_time = time.time()\n",
        "\n",
        "      running_loss = 0.0\n",
        "      running_loss_for_epoch = 0.0\n",
        "\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          \n",
        "          # Get the inputs\n",
        "          inputs, labels = data\n",
        "          \n",
        "\n",
        "          # Wrap them in Variable\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          # Zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Forward + backward + optimize\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs,labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "\n",
        "          # Print statistics\n",
        "          running_loss += loss.item()\n",
        "          running_loss_for_epoch += loss.item()\n",
        "          if i % 100 == 99:    # print every 100 mini-batches\n",
        "              print('[epoch : %d, minibatch : %5d] loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, running_loss / 100))\n",
        "              running_loss = 0.0\n",
        "\n",
        "          correct = 0\n",
        "          total = 0\n",
        "\n",
        "      for i, data in enumerate(testloader, 0):\n",
        "          inputs, labels = data\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      print('Accuracy of the network on the {} test images: {:4.2f} %'.format(\n",
        "          testset.data.shape[0], 100 * (correct / total)))\n",
        "\n",
        "      finish_time = (time.time() - start_time)\n",
        "      batches_pr_epoch = math.ceil(trainset.data.shape[0] / BATCH_SIZE)\n",
        "      loss_pr_epoch.append(running_loss_for_epoch / batches_pr_epoch)\n",
        "      accuracies.append(100 * (correct / total))\n",
        "      batch_sizes.append(BATCH_SIZE)\n",
        "      epochs.append(epoch)\n",
        "      time_pr_epoch.append(finish_time)\n",
        "      \n",
        "    \n",
        "  print('Finished Training')\n",
        "\n",
        "  \n",
        "print(\"loss pr epoch\", loss_pr_epoch)\n",
        "print(\"accuracies\", accuracies)\n",
        "print(\"batch_sizes\", batch_sizes)\n",
        "print(\"epochs\", epochs)\n",
        "print(\"time_pr_epoch\", time_pr_epoch)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "######### BATCH SIZE =  2048  ######### \n",
            "Warmup for  3.5  epochs.\n",
            "warmup LR:  0.18101933598375616\n",
            "Accuracy of the network on the 10000 test images: 29.64 %\n",
            "warmup LR:  0.3620386719675123\n",
            "Accuracy of the network on the 10000 test images: 18.11 %\n",
            "warmup LR:  0.7240773439350247\n",
            "Accuracy of the network on the 10000 test images: 12.86 %\n",
            "Accuracy of the network on the 10000 test images: 22.02 %\n",
            "Accuracy of the network on the 10000 test images: 22.65 %\n",
            "Accuracy of the network on the 10000 test images: 14.80 %\n",
            "Accuracy of the network on the 10000 test images: 23.78 %\n",
            "Accuracy of the network on the 10000 test images: 33.06 %\n",
            "Accuracy of the network on the 10000 test images: 34.23 %\n",
            "Accuracy of the network on the 10000 test images: 29.86 %\n",
            "Accuracy of the network on the 10000 test images: 40.77 %\n",
            "Accuracy of the network on the 10000 test images: 46.27 %\n",
            "Accuracy of the network on the 10000 test images: 42.52 %\n",
            "Accuracy of the network on the 10000 test images: 51.43 %\n",
            "Accuracy of the network on the 10000 test images: 48.87 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-323b8b566788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m           \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m           \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m           \u001b[0mrunning_loss_for_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# print every 100 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzc-qq2NKrFo"
      },
      "source": [
        "## 4. Saving results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI_RMRJ-Kvl5"
      },
      "source": [
        "#### Results are saved in a tab-seperated csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p87SYVOAjH6"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "results = pd.DataFrame(\n",
        "    {'batch_size': batch_sizes,\n",
        "     'epoch': epochs,\n",
        "     'accuracy': accuracies,\n",
        "     'loss': loss_pr_epoch,\n",
        "     'time': time_pr_epoch\n",
        "    })\n",
        "\n",
        "results.to_csv('gdrive/MyDrive/results_large_batches_scaled_lr_warmup.csv', sep ='\\t')"
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}